{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5863298,"sourceType":"datasetVersion","datasetId":3371317}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.python.keras.layers import Dense, Flatten\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2024-10-20T12:33:13.580488Z","iopub.execute_input":"2024-10-20T12:33:13.580968Z","iopub.status.idle":"2024-10-20T12:33:26.702350Z","shell.execute_reply.started":"2024-10-20T12:33:13.580915Z","shell.execute_reply":"2024-10-20T12:33:26.701491Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import tensorflow as tf\nimport os\n\n# Specify the classes to include (excluding the specified fruits/vegetables)\nincluded_classes = [\n    'freshbanana',\n    'freshcapsicum',\n    'freshcucumber',\n    'freshoranges',\n    'freshpotato',\n    'freshtomato',\n    'rottenbanana',\n    'rottencapsicum',\n    'rottencucumber',\n    'rottenoranges',\n    'rottenpotato',\n    'rottentomato'\n]\n\nimg_height, img_width = 180, 180\nbatch_size = 64\ndataset_dir = \"/kaggle/input/fresh-and-stale-classification/dataset/Train\"\n\n# Function to count the number of images in each class\ndef count_images_per_class(directory, classes):\n    class_counts = {}\n    for class_name in classes:\n        class_dir = os.path.join(directory, class_name)\n        if os.path.exists(class_dir):\n            image_count = len(os.listdir(class_dir))\n            class_counts[class_name] = image_count\n        else:\n            class_counts[class_name] = 0  # If the class directory doesn't exist\n    return class_counts\n\n# Count images in each class\nimage_counts = count_images_per_class(dataset_dir, included_classes)\n\n# Print the counts for each class\nprint(\"Number of images per class:\")\nfor class_name, count in image_counts.items():\n    print(f\"{class_name}: {count} images\")\n\n# Load the training dataset while excluding certain classes\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    dataset_dir,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=123,\n    image_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_names=included_classes  # Include only the specified classes\n)\n\n# Load the validation dataset using the same classes\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    dataset_dir,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=123,\n    image_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_names=included_classes  # Include only the specified classes\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T12:33:26.704273Z","iopub.execute_input":"2024-10-20T12:33:26.705281Z","iopub.status.idle":"2024-10-20T12:33:41.121813Z","shell.execute_reply.started":"2024-10-20T12:33:26.705232Z","shell.execute_reply":"2024-10-20T12:33:41.121005Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Number of images per class:\nfreshbanana: 2468 images\nfreshcapsicum: 990 images\nfreshcucumber: 496 images\nfreshoranges: 1466 images\nfreshpotato: 536 images\nfreshtomato: 1858 images\nrottenbanana: 2932 images\nrottencapsicum: 901 images\nrottencucumber: 421 images\nrottenoranges: 1595 images\nrottenpotato: 802 images\nrottentomato: 1825 images\nFound 16290 files belonging to 12 classes.\nUsing 13032 files for training.\nFound 16290 files belonging to 12 classes.\nUsing 3258 files for validation.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from tensorflow.keras import layers, models\n\n# Load the pretrained ResNet50 model without the top layer\npretrained_model = tf.keras.applications.ResNet50(\n    include_top=False,\n    input_shape=(180, 180, 3),\n    pooling='avg',\n    weights='imagenet'\n)\n\n# Freeze the layers in the pretrained model\nfor layer in pretrained_model.layers:\n    layer.trainable = False\n\n# Create a new input layer\ninputs = layers.Input(shape=(180, 180, 3))\n\n# Pass the inputs through the pretrained model\nx = pretrained_model(inputs)\n\n# Add your custom layers on top\nx = layers.Dense(512, activation='relu')(x)\noutputs = layers.Dense(12, activation='softmax')(x)\n\n# Create the full model\nresnet_model = models.Model(inputs, outputs)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T12:33:41.122939Z","iopub.execute_input":"2024-10-20T12:33:41.123256Z","iopub.status.idle":"2024-10-20T12:33:43.105028Z","shell.execute_reply.started":"2024-10-20T12:33:41.123224Z","shell.execute_reply":"2024-10-20T12:33:43.104196Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"resnet_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-10-20T12:33:43.106969Z","iopub.execute_input":"2024-10-20T12:33:43.107272Z","iopub.status.idle":"2024-10-20T12:33:43.136093Z","shell.execute_reply.started":"2024-10-20T12:33:43.107240Z","shell.execute_reply":"2024-10-20T12:33:43.135172Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │    \u001b[38;5;34m23,587,712\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,049,088\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │         \u001b[38;5;34m6,156\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,156</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,642,956\u001b[0m (94.01 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,642,956</span> (94.01 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,055,244\u001b[0m (4.03 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,055,244</span> (4.03 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n</pre>\n"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n# Compile the model\nresnet_model.compile(\n    optimizer=Adam(learning_rate=0.001),  # Optimizer with the initial learning rate\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-20T12:33:43.137387Z","iopub.execute_input":"2024-10-20T12:33:43.138172Z","iopub.status.idle":"2024-10-20T12:33:43.154845Z","shell.execute_reply.started":"2024-10-20T12:33:43.138137Z","shell.execute_reply":"2024-10-20T12:33:43.154093Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"epochs=10\nhistory = resnet_model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs,\n    callbacks=EarlyStopping(\n    monitor='val_loss',  # You can also monitor 'val_accuracy'\n    patience=3,          # Number of epochs with no improvement after which training will be stopped\n    restore_best_weights=True  # Restores the model weights from the best epoch\n)\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-20T12:33:43.156103Z","iopub.execute_input":"2024-10-20T12:33:43.156383Z","iopub.status.idle":"2024-10-20T12:37:43.724322Z","shell.execute_reply.started":"2024-10-20T12:33:43.156352Z","shell.execute_reply":"2024-10-20T12:37:43.723338Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1729427630.005191      81 service.cc:145] XLA service 0x7f6538012140 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1729427630.005255      81 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  3/204\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.1641 - loss: 3.0247","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1729427635.261766      81 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 228ms/step - accuracy: 0.8371 - loss: 0.6041 - val_accuracy: 0.9678 - val_loss: 0.0923\nEpoch 2/10\n\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 108ms/step - accuracy: 0.9759 - loss: 0.0703 - val_accuracy: 0.9794 - val_loss: 0.0654\nEpoch 3/10\n\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 107ms/step - accuracy: 0.9865 - loss: 0.0417 - val_accuracy: 0.9850 - val_loss: 0.0441\nEpoch 4/10\n\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 106ms/step - accuracy: 0.9883 - loss: 0.0330 - val_accuracy: 0.9843 - val_loss: 0.0437\nEpoch 5/10\n\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 138ms/step - accuracy: 0.9903 - loss: 0.0295 - val_accuracy: 0.9847 - val_loss: 0.0449\nEpoch 6/10\n\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 110ms/step - accuracy: 0.9946 - loss: 0.0172 - val_accuracy: 0.9868 - val_loss: 0.0418\nEpoch 7/10\n\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 108ms/step - accuracy: 0.9952 - loss: 0.0137 - val_accuracy: 0.9800 - val_loss: 0.0549\nEpoch 8/10\n\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 105ms/step - accuracy: 0.9926 - loss: 0.0226 - val_accuracy: 0.9828 - val_loss: 0.0595\nEpoch 9/10\n\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 107ms/step - accuracy: 0.9911 - loss: 0.0302 - val_accuracy: 0.9638 - val_loss: 0.1045\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Save model weights with the required filename ending\nmodel_weights_path = '/kaggle/working/resnet_model_weights.weights.h5'  # Ensure it ends with .weights.h5\nresnet_model.save_weights(model_weights_path)\nprint(f\"Model weights saved to {model_weights_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T12:37:43.725576Z","iopub.execute_input":"2024-10-20T12:37:43.725870Z","iopub.status.idle":"2024-10-20T12:37:44.158176Z","shell.execute_reply.started":"2024-10-20T12:37:43.725839Z","shell.execute_reply":"2024-10-20T12:37:44.157214Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Model weights saved to /kaggle/working/resnet_model_weights.weights.h5\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import shutil\n\n# Zip the model weights\nshutil.make_archive('/kaggle/working/resnet_model_weights', 'zip', '/kaggle/working', 'resnet_model_weights.weights.h5')\nprint(\"Model weights zipped and ready for download.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T12:37:44.159323Z","iopub.execute_input":"2024-10-20T12:37:44.159631Z","iopub.status.idle":"2024-10-20T12:37:50.136425Z","shell.execute_reply.started":"2024-10-20T12:37:44.159599Z","shell.execute_reply":"2024-10-20T12:37:50.135404Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Model weights zipped and ready for download.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.utils import class_weight\n\n# Number of images per class\nclass_counts = {\n    'freshbanana': 2468,\n    'freshcapsicum': 990,\n    'freshcucumber': 496,\n    'freshoranges': 1466,\n    'freshpotato': 536,\n    'freshtomato': 1858,\n    'rottenbanana': 2932,\n    'rottencapsicum': 901,\n    'rottencucumber': 421,\n    'rottenoranges': 1595,\n    'rottenpotato': 802,\n    'rottentomato': 1825\n}\n\n# Total number of images\ntotal_images = sum(class_counts.values())\n# Calculate class weights\nclass_weights = {i: total_images / (len(class_counts) * count) for i, count in enumerate(class_counts.values())}\n\n# Load the pretrained ResNet50 model without the top layer\npretrained_model = tf.keras.applications.ResNet50(\n    include_top=False,\n    input_shape=(180, 180, 3),\n    pooling='avg',\n    weights='imagenet'\n)\n\n# Freeze the layers in the pretrained model\nfor layer in pretrained_model.layers:\n    layer.trainable = False\n\n# Create a new input layer\ninputs = layers.Input(shape=(180, 180, 3))\n\n# Pass the inputs through the pretrained model\nx = pretrained_model(inputs)\n\n# Add your custom layers on top\nx = layers.Dense(512, activation='relu')(x)\noutputs = layers.Dense(len(class_counts), activation='softmax')(x)  # Adjusted for number of classes\n\n# Create the full model\nresnet_model = models.Model(inputs, outputs)\n\n# Compile the model\nresnet_model.compile(\n    optimizer=Adam(learning_rate=0.001),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Define the number of epochs\nepochs = 10\n\n# Train the model with class weights\nhistory = resnet_model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=epochs,\n    class_weight=class_weights,  # Add class weights here\n    callbacks=[EarlyStopping(\n        monitor='val_loss',\n        patience=3,\n        restore_best_weights=True\n    )]\n)\n\n# Print the model summary\nresnet_model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T12:37:50.137867Z","iopub.execute_input":"2024-10-20T12:37:50.138567Z","iopub.status.idle":"2024-10-20T12:41:43.896092Z","shell.execute_reply.started":"2024-10-20T12:37:50.138520Z","shell.execute_reply":"2024-10-20T12:41:43.895173Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 134ms/step - accuracy: 0.8415 - loss: 0.6390 - val_accuracy: 0.9699 - val_loss: 0.0937\nEpoch 2/10\n\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 106ms/step - accuracy: 0.9783 - loss: 0.1066 - val_accuracy: 0.9776 - val_loss: 0.0679\nEpoch 3/10\n\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 107ms/step - accuracy: 0.9840 - loss: 0.0841 - val_accuracy: 0.9807 - val_loss: 0.0576\nEpoch 4/10\n\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 105ms/step - accuracy: 0.9883 - loss: 0.0560 - val_accuracy: 0.9724 - val_loss: 0.0986\nEpoch 5/10\n\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 107ms/step - accuracy: 0.9903 - loss: 0.0405 - val_accuracy: 0.9828 - val_loss: 0.0540\nEpoch 6/10\n\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 108ms/step - accuracy: 0.9940 - loss: 0.0307 - val_accuracy: 0.9862 - val_loss: 0.0359\nEpoch 7/10\n\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 107ms/step - accuracy: 0.9923 - loss: 0.0274 - val_accuracy: 0.9776 - val_loss: 0.0676\nEpoch 8/10\n\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 109ms/step - accuracy: 0.9958 - loss: 0.0225 - val_accuracy: 0.9871 - val_loss: 0.0399\nEpoch 9/10\n\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 110ms/step - accuracy: 0.9943 - loss: 0.0307 - val_accuracy: 0.9850 - val_loss: 0.0493\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │    \u001b[38;5;34m23,587,712\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,049,088\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │         \u001b[38;5;34m6,156\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,156</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,753,446\u001b[0m (102.06 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,753,446</span> (102.06 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,055,244\u001b[0m (4.03 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,055,244</span> (4.03 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,110,490\u001b[0m (8.05 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,110,490</span> (8.05 MB)\n</pre>\n"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# Save model weights with the required filename ending\nmodel_weights_path = '/kaggle/working/resnet_model_weights.weights.h5'  # Ensure it ends with .weights.h5\nresnet_model.save_weights(model_weights_path)\nprint(f\"Model weights saved to {model_weights_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-20T12:41:43.898479Z","iopub.execute_input":"2024-10-20T12:41:43.899066Z","iopub.status.idle":"2024-10-20T12:41:44.401861Z","shell.execute_reply.started":"2024-10-20T12:41:43.899031Z","shell.execute_reply":"2024-10-20T12:41:44.400900Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Model weights saved to /kaggle/working/resnet_model_weights.weights.h5\n","output_type":"stream"}],"execution_count":10}]}